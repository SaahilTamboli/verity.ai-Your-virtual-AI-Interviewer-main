<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Verity AI Interview</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/js/all.min.js"></script>
    <style>
        :root {
            --primary-color: #00FFFF;
            --secondary-color: #FF00FF;
            --background-color: #0A0A0A;
            --text-color: #E2E8F0;
            --accent-glow: 0 0 20px rgba(0, 255, 255, 0.5);
        }
        body {
            font-family: 'Montserrat', sans-serif;
            background-color: var(--background-color);
            color: var(--text-color);
            position: relative;
            overflow: hidden;
        }
        body::before {
            content: "";
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                linear-gradient(45deg, rgba(0, 255, 255, 0.05), rgba(255, 0, 255, 0.05)),
                url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100' height='100' viewBox='0 0 100 100'%3E%3Cg fill-rule='evenodd'%3E%3Cg fill='%2300FFFF' fill-opacity='0.05'%3E%3Cpath opacity='.5' d='M96 95h4v1h-4v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4h-9v4h-1v-4H0v-1h15v-9H0v-1h15v-9H0v-1h15v-9H0v-1h15v-9H0v-1h15v-9H0v-1h15v-9H0v-1h15v-9H0v-1h15V0h1v15h9V0h1v15h9V0h1v15h9V0h1v15h9V0h1v15h9V0h1v15h9V0h1v15h9V0h1v15h9V0h1v15h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9h4v1h-4v9zm-1 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-9-10h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm9-10v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-10 0v-9h-9v9h9zm-9-10h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9zm10 0h9v-9h-9v9z'/%3E%3Cpath d='M6 5V0H5v5H0v1h5v94h1V6h94V5H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
            pointer-events: none;
            z-index: -1;
        }
        .btn-nexus {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: var(--text-color);
            transition: all 0.3s ease;
        }
        .btn-nexus:hover {
            transform: translateY(-2px);
            box-shadow: var(--accent-glow);
        }
        #interview-transcript {
            background-color: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(5px);
        }
        .message {
            padding: 10px;
            margin-bottom: 10px;
            border-radius: 10px;
        }
        .interviewer {
            background-color: rgba(0, 255, 255, 0.1);
            border-left: 3px solid var(--primary-color);
        }
        .system {
            background-color: rgba(255, 0, 255, 0.1);
            border-left: 3px solid var(--secondary-color);
        }
    </style>
</head>
<body class="min-h-screen flex items-center justify-center p-4">
    <div class="w-full max-w-6xl p-8 rounded-lg bg-gray-800 bg-opacity-80 shadow-2xl backdrop-filter backdrop-blur-lg">
        <h1 class="text-4xl font-bold mb-8 text-center text-transparent bg-clip-text bg-gradient-to-r from-cyan-400 to-pink-400">Verity AI Interview</h1>

        <div id="interview-room" class="space-y-6">
            <div id="interview-transcript" class="h-96 overflow-y-auto p-6 rounded-lg"></div>
            <div class="flex justify-center space-x-4 mt-8">
                <button id="start-interview" class="btn-nexus font-bold py-3 px-6 rounded-full shadow-lg hover:shadow-xl flex items-center">
                    <i class="fas fa-play mr-2"></i> Start Interview
                </button>
                <button id="record-response" class="btn-nexus font-bold py-3 px-6 rounded-full shadow-lg hover:shadow-xl flex items-center" disabled>
                    <i class="fas fa-microphone mr-2"></i> Record Response
                </button>
                <button id="end-interview" class="bg-red-600 hover:bg-red-700 text-white font-bold py-3 px-6 rounded-full shadow-lg hover:shadow-xl transition duration-300 flex items-center">
                    <i class="fas fa-times mr-2"></i> End Interview
                </button>
            </div>
        </div>
    </div>

    <script>
        const chatArea = document.getElementById('interview-transcript');
        const startInterviewButton = document.getElementById('start-interview');
        const recordResponseButton = document.getElementById('record-response');
        const endInterviewButton = document.getElementById('end-interview');
        let ws;
        let audioContext;
        let audioQueue = [];
        let isPlayingAudio = false;

        const jobRole = {{ job_role|tojson|safe }};
        const jobDescription = {{ job_description|tojson|safe }};
        const interviewId = '{{ interview_id }}';
        const userId = '{{ user_id }}';
        const isEnterprise = {{ is_enterprise|default(false)|tojson }};
        const documentUrl = {{ document_url|default('')|tojson|safe }};

        startInterviewButton.addEventListener('click', startInterview);
        recordResponseButton.addEventListener('click', recordResponse);
        endInterviewButton.addEventListener('click', endInterview);

        async function startInterview() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsEndpoint = isEnterprise ? 'enterprise-interview-ws' : 'interview-ws';
            ws = new WebSocket(`${protocol}//${window.location.host}/user/${wsEndpoint}/${interviewId}?user_id=${userId}`);
            
            ws.onopen = () => {
                console.log('WebSocket connected');
                startInterviewButton.disabled = true;
                recordResponseButton.disabled = false;
                addMessage('Interview started. Waiting for the first question...', 'system');
                
                setTimeout(() => {
                    ws.send(JSON.stringify({type: 'start'}));
                }, 1000);
            };
            ws.onmessage = handleWebSocketMessage;
            ws.onclose = () => console.log('WebSocket disconnected');
            ws.onerror = (error) => console.error('WebSocket error:', error);

            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }

        async function handleWebSocketMessage(event) {
            console.log("Received WebSocket message", event);
            if (event.data instanceof Blob) {
                console.log("Received audio chunk", event.data.size);
                const arrayBuffer = await event.data.arrayBuffer();
                audioQueue.push(new Float32Array(arrayBuffer));
                if (!isPlayingAudio) {
                    playNextAudioChunk();
                }
            } else {
                try {
                    const data = JSON.parse(event.data);
                    console.log("Received parsed message:", data);
                    switch (data.type) {
                        case 'text':
                            addMessage(data.content, 'interviewer');
                            break;
                        case 'audio':
                            // Display the text content of the audio message
                            if (data.text) {
                                addMessage(data.text, 'interviewer');
                            }
                            // Handle audio chunk (already being done in the Blob case)
                            break;
                        case 'audio_end':
                            console.log('Audio playback complete');
                            break;
                        case 'info':
                            console.log(data.content);
                            break;
                        case 'error':
                            console.error(data.content);
                            addMessage(`Error: ${data.content}`, 'system');
                            break;
                    }
                } catch (error) {
                    console.error("Error parsing WebSocket message:", error);
                }
            }
        }

        async function playNextAudioChunk() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                return;
            }

            isPlayingAudio = true;
            const audioChunk = audioQueue.shift();

            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            if (audioChunk.length === 0) {
                console.warn("Received empty audio chunk, skipping");
                playNextAudioChunk();
                return;
            }

            const buffer = audioContext.createBuffer(1, audioChunk.length, 48000);
            buffer.getChannelData(0).set(audioChunk);
            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            source.onended = playNextAudioChunk;
            source.start(0);
        }

        function addMessage(text, sender) {
            const messageContainer = document.createElement('div');
            messageContainer.classList.add('message-container');

            const message = document.createElement('div');
            message.classList.add('message', sender);
            message.textContent = text;
            
            messageContainer.appendChild(message);
            chatArea.appendChild(messageContainer);
            chatArea.scrollTop = chatArea.scrollHeight;
        }

        let isRecording = false;

        function recordResponse() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }

        function startRecording() {
            isRecording = true;
            recordResponseButton.textContent = 'Stop Recording';
            ws.send(JSON.stringify({type: 'start_recording'}));
            addMessage('Recording started...', 'system');
        }

        function stopRecording() {
            isRecording = false;
            recordResponseButton.textContent = 'Record Response';
            ws.send(JSON.stringify({type: 'stop_recording'}));
            addMessage('Recording stopped. Processing your response...', 'system');
        }

        function endInterview() {
            if (confirm("Are you sure you want to end the interview?")) {
                ws.send(JSON.stringify({ type: 'end_interview' }));
                ws.close();
                window.location.href = '/';
            }
        }
    </script>
</body>
</html>
